---
title: "Functions"
format: html
---

The code in this script generates tables for the manuscript.

::: Rcode
### Source code

The full R script is available at:

-   [`R/functions.R`](https://github.com/VagishHemmige/OPE-CDC-analysis-2026/blob/master/R/functions.R)

This R script file is itself reliant on the following helper files:

-   [`R/setup.R`](https://github.com/VagishHemmige/OPE-CDC-analysis-2026/blob/master/R/setup.R)
:::

## Drawing 60 minute isocrhones around each transplant center

The following function uses the [`mapboxapi` package](https://walker-data.com/mapboxapi/) to calculate 60-minute travel isochrones around each
transplant center.

The function assumes the that you have an API token configured in R.  For details of how to do this, see the package documentation.

Its inputs are as follows:

- `SFObject`: This is an object of class `sf` that contains the location of each transplant center
- `year`: year as a character.  Must be a year in `yearlist` defined in `R/setup.R`.


```{r, eval=FALSE}



#Define a function that takes an SF data object and returns 60 minute isochrones
set_60_min_isochrone_at_7AM<-function(SFObject, year) {
  
  if (nrow(SFObject) == 0) {
    return(
      SFObject %>%
        st_transform(5070)
    )
  }else{
    tempDF<-SFObject%>%
      mutate(TimeZone=tz_lookup(., method="accurate"))%>%
      st_transform(4326)
    
    FinalDF <- vector("list", length(timezones))
    
    
    for(i in 1:length(timezones))
    {
      TZ<-converted_times[[year]][[i,1]]
      
      UTCTime<-format(converted_times[[year]][[i,3]], "%Y-%m-%dT%H:%M:%SZ")
      
      if (nrow(filter(tempDF,TimeZone==TZ))>0)
      {
        temp<-tempDF%>%
          filter(TimeZone==TZ)%>%
          mb_isochrone(time = 60, 
                       profile = "driving-traffic",
                       depart_at = UTCTime,
                       id_column = "OTCCode")%>%
          rename(OTCCode=id)
        FinalDF[[i]]<-temp
      }
    }
    
    FinalDF%>%
      bind_rows()%>%
      st_transform(5070)%>%
      return()
  }
}


```


## Calculating the number of potential matches

The above function is passed a control df and a number of values for a case patient, and returns the number of distinct controls which are potential matches.
The matching algorithm is hard-coded.

```{r, eval=FALSE}
#Function that defines the number of potential control matches for a case
calculate_number_potential_matches<-function(control_df,
                                             USRDS_ID,
                                             birthdate,
                                             cirrhosis_status,
                                             cmv_status,
                                             hiv_status,
                                             diabetes_status,
                                             matching_date,
                                             matching_days_since_transplant) {
  
  print(paste0("Calculating number of potential controls for patient: ", USRDS_ID))
  control_df%>%
    
    #Exact match on cirrhosis, CMV, HIV, and diabetes status
    filter(cirrhosis==cirrhosis_status)%>%
    #  filter(CMV==cmv_status)%>%
    filter(HIV==hiv_status)%>%
    filter(diabetes==diabetes_status)%>%
    
    #Risk set matching
    filter(tstart<=matching_days_since_transplant)%>%
    filter(tstop>matching_days_since_transplant)%>%
    
    #Calculate date for age calculations/etc.
    mutate(.baseline_control_date=matching_days_since_transplant+most_recent_transplant_date)%>%
    
    #Make sure case and control are sampled within 3 years of each other
    filter(abs(time_length(interval(.baseline_control_date, matching_date), "years")) <=3)%>%
    
    #Date matching
    #  filter(cohort_start_date<=matching_date)%>%
    #  filter(cohort_stop_date>matching_date)%>%
    
    #Age>=18 on index date
    filter(time_length(interval(BORN, .baseline_control_date), "years") >= 18)%>%
    
    #Age difference under 10 years, calculated at sampling date
    filter(abs(time_length(interval(BORN,.baseline_control_date), "years")-
                 time_length(interval(birthdate,matching_date), "years")) <=10)%>%
    
    #Confirming 365 day Medicare lookback available for potential match
    verify_medicare_primary(index_date = matching_date, medicare_coverage_df = medicare_history, cache=TRUE)%>%
    filter(medicare_primary_TF==TRUE)%>%
    
    #Count rows after ensuring controls with mult transplants are only counted once 
    distinct(USRDS_ID)%>%
    nrow()%>%
    return()
  
}

```


## Total excess costs

This function takes a `fit` object from a model and calculates the total estimated excess costs and confidence intervals.
This object currently only works for models with linear links.

```{r, eval=FALSE}


# Calculate total excess costs in a model
calculate_total_excess_costs <- function(fitted_model, link = "linear") {
  
  # Extract coefficients and vcov matrix
  coef_df <- tidy(fitted_model)
  vcov_matrix <- vcov(fitted_model)
  
  # Get interaction terms
  interaction_names <- coef_df %>% 
    filter(str_detect(term, ":")) %>% 
    pull(term)
  
  if (link == "linear") {
    # Sum of coefficients
    sum_estimate <- coef_df %>% 
      filter(term %in% interaction_names) %>% 
      pull(estimate) %>% 
      sum()
    
    # Variance of sum
    sum_variance <- vcov_matrix[interaction_names, interaction_names] %>% 
      sum()
    
    # Standard error and CI
    sum_se <- sqrt(sum_variance)
    df <- df.residual(fitted_model)
    
    tibble(
      estimate = sum_estimate,
      std_error = sum_se,
      conf_low = estimate - qt(0.975, df) * std_error,
      conf_high = estimate + qt(0.975, df) * std_error,
      statistic = estimate / std_error,
      p_value = 2 * pt(-abs(statistic), df)
    )
    
  } else if (link == "log") {
    # Get coefficients for interactions
    coefs <- coef(fitted_model)[interaction_names]
    vcov_sub <- vcov_matrix[interaction_names, interaction_names]
    
    # Exponentiate each coefficient
    exp_coefs <- exp(coefs)
    
    # Sum of exponentiated coefficients
    sum_estimate <- sum(exp_coefs)
    
    # Delta method for variance
    # Gradient: derivative of sum(exp(beta)) w.r.t. each beta is exp(beta)
    gradient <- exp_coefs
    
    # Variance using delta method
    sum_variance <- as.numeric(t(gradient) %*% vcov_sub %*% gradient)
    sum_se <- sqrt(sum_variance)
    
    # CI using normal approximation (GLM)
    tibble(
      estimate = sum_estimate,
      std_error = sum_se,
      conf_low = estimate - qnorm(0.975) * std_error,
      conf_high = estimate + qnorm(0.975) * std_error,
      statistic = estimate / std_error,
      p_value = 2 * pnorm(-abs(statistic))
    )
    
  } else {
    stop("link must be either 'linear' or 'log'")
  }
}

```



## Other portions of the analysis


-   [**Setup**](setup.qmd): Defines global paths, data sources, cohort inclusion criteria, and analysis-wide constants.
-   [**Tables**](tables.qmd): Summary tables and regression outputs generated from the final models.
-   [**Figures**](figures.qmd):Visualizations of costs, risks, and model-based estimates.
-   [**About**](about.qmd): methods, assumptions, and disclosures
